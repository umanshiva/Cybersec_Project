{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "\n",
    "# Define the function\n",
    "def train_and_serve_model(data_path, model_path=\"model.h5\"):\n",
    "    \"\"\"\n",
    "    Train a neural network on the NUSW-NB15 dataset and save the model for serving.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the CSV dataset.\n",
    "        model_path (str): Path to save the trained model (default: \"model.h5\").\n",
    "    Returns:\n",
    "        str: Message indicating training completion and model saving.\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    # Encode categorical features\n",
    "    categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        data[col] = LabelEncoder().fit_transform(data[col])\n",
    "    \n",
    "    # Split into features (X) and target (y)\n",
    "    X = data.drop(columns=['class'], axis=1)  # Assuming 'class' is the target\n",
    "    y = data['class']\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Encode target labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    y_categorical = to_categorical(y_encoded)\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Build the neural network\n",
    "    model = Sequential([\n",
    "        Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(y_categorical.shape[1], activation='softmax')  # Output layer\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1)\n",
    "    \n",
    "    # Save the trained model\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # Save the scaler and label encoder for consistent preprocessing\n",
    "    np.save(\"scaler.npy\", scaler)\n",
    "    np.save(\"label_encoder.npy\", label_encoder.classes_)\n",
    "    \n",
    "    return f\"Model trained and saved to {model_path}\"\n",
    "\n",
    "def predict(input_data, model_path=\"model.h5\"):\n",
    "    \"\"\"\n",
    "    Predict the class of new input data using the trained model.\n",
    "\n",
    "    Args:\n",
    "        input_data (list): List of input features (single instance).\n",
    "        model_path (str): Path to the trained model (default: \"model.h5\").\n",
    "    Returns:\n",
    "        str: Predicted class label.\n",
    "    \"\"\"\n",
    "    # Load the trained model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Load the scaler and label encoder\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler = scaler.fit(np.load(\"scaler.npy\", allow_pickle=True))\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.classes_ = np.load(\"label_encoder.npy\", allow_pickle=True)\n",
    "    \n",
    "    # Preprocess input data\n",
    "    input_data = scaler.transform([input_data])\n",
    "    \n",
    "    # Predict the class\n",
    "    predictions = model.predict(input_data)\n",
    "    predicted_class = label_encoder.inverse_transform([np.argmax(predictions)])\n",
    "    \n",
    "    return predicted_class[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
